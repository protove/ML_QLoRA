{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 27.25860595703125,
      "learning_rate": 5.882352941176471e-05,
      "loss": 14.7047,
      "step": 10
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 47.12974548339844,
      "learning_rate": 0.00011764705882352942,
      "loss": 11.8542,
      "step": 20
    },
    {
      "epoch": 0.08,
      "grad_norm": 27.37681770324707,
      "learning_rate": 0.00017647058823529413,
      "loss": 4.7422,
      "step": 30
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.8208048939704895,
      "learning_rate": 0.00019998507508226524,
      "loss": 0.8707,
      "step": 40
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.3758561313152313,
      "learning_rate": 0.0001998938833847273,
      "loss": 0.3143,
      "step": 50
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39744439721107483,
      "learning_rate": 0.00019971986712829932,
      "loss": 0.3177,
      "step": 60
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.17063282430171967,
      "learning_rate": 0.00019946317059428448,
      "loss": 0.2782,
      "step": 70
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.19568085670471191,
      "learning_rate": 0.00019912400661630658,
      "loss": 0.2633,
      "step": 80
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1724325269460678,
      "learning_rate": 0.00019870265640384435,
      "loss": 0.2661,
      "step": 90
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.15241079032421112,
      "learning_rate": 0.00019819946930907332,
      "loss": 0.2201,
      "step": 100
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.22586922347545624,
      "learning_rate": 0.00019761486253720915,
      "loss": 0.2199,
      "step": 110
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.19289827346801758,
      "learning_rate": 0.00019694932080059217,
      "loss": 0.2298,
      "step": 120
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.2015332132577896,
      "learning_rate": 0.00019620339591680023,
      "loss": 0.2459,
      "step": 130
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.2247902899980545,
      "learning_rate": 0.0001953777063511223,
      "loss": 0.2276,
      "step": 140
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.2657341957092285,
      "learning_rate": 0.0001944729367037736,
      "loss": 0.2604,
      "step": 150
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.20979838073253632,
      "learning_rate": 0.00019348983714227583,
      "loss": 0.245,
      "step": 160
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.1596958488225937,
      "learning_rate": 0.00019242922277947448,
      "loss": 0.2271,
      "step": 170
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.20096412301063538,
      "learning_rate": 0.0001912919729977078,
      "loss": 0.2305,
      "step": 180
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.18114672601222992,
      "learning_rate": 0.00019007903071968868,
      "loss": 0.2284,
      "step": 190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.156971737742424,
      "learning_rate": 0.00018879140162670347,
      "loss": 0.2473,
      "step": 200
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.19956058263778687,
      "learning_rate": 0.00018743015332477588,
      "loss": 0.2729,
      "step": 210
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.16786880791187286,
      "learning_rate": 0.0001859964144594879,
      "loss": 0.2183,
      "step": 220
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.17999745905399323,
      "learning_rate": 0.00018449137378019094,
      "loss": 0.2345,
      "step": 230
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.17589399218559265,
      "learning_rate": 0.00018291627915438348,
      "loss": 0.238,
      "step": 240
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.28619658946990967,
      "learning_rate": 0.00018127243653307248,
      "loss": 0.2347,
      "step": 250
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.2202073484659195,
      "learning_rate": 0.00017956120886797604,
      "loss": 0.2558,
      "step": 260
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.18816402554512024,
      "learning_rate": 0.0001777840149814657,
      "loss": 0.2065,
      "step": 270
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.15398389101028442,
      "learning_rate": 0.0001759423283901846,
      "loss": 0.238,
      "step": 280
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.21115277707576752,
      "learning_rate": 0.00017403767608331733,
      "loss": 0.2321,
      "step": 290
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1511969119310379,
      "learning_rate": 0.00017207163725652445,
      "loss": 0.2552,
      "step": 300
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.16145110130310059,
      "learning_rate": 0.00017004584200259107,
      "loss": 0.2458,
      "step": 310
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.17024432122707367,
      "learning_rate": 0.0001679619699598757,
      "loss": 0.2352,
      "step": 320
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.18428635597229004,
      "learning_rate": 0.0001658217489196792,
      "loss": 0.2176,
      "step": 330
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.14989297091960907,
      "learning_rate": 0.00016362695339368913,
      "loss": 0.22,
      "step": 340
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.20755115151405334,
      "learning_rate": 0.00016137940314268695,
      "loss": 0.2333,
      "step": 350
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.171951562166214,
      "learning_rate": 0.00015908096166773817,
      "loss": 0.2483,
      "step": 360
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.18277516961097717,
      "learning_rate": 0.00015673353466511618,
      "loss": 0.2434,
      "step": 370
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 0.19349922239780426,
      "learning_rate": 0.0001543390684462409,
      "loss": 0.2197,
      "step": 380
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.17880307137966156,
      "learning_rate": 0.00015189954832394266,
      "loss": 0.2038,
      "step": 390
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.23251882195472717,
      "learning_rate": 0.00014941699696638887,
      "loss": 0.2461,
      "step": 400
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 0.17066830396652222,
      "learning_rate": 0.00014689347272003813,
      "loss": 0.213,
      "step": 410
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.17257541418075562,
      "learning_rate": 0.0001443310679030132,
      "loss": 0.2412,
      "step": 420
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 0.15600326657295227,
      "learning_rate": 0.0001417319070703066,
      "loss": 0.242,
      "step": 430
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 0.15979839861392975,
      "learning_rate": 0.0001390981452522581,
      "loss": 0.2442,
      "step": 440
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.18101389706134796,
      "learning_rate": 0.00013643196616776432,
      "loss": 0.2196,
      "step": 450
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.20310018956661224,
      "learning_rate": 0.00013373558041370178,
      "loss": 0.2217,
      "step": 460
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.17299842834472656,
      "learning_rate": 0.00013101122363206488,
      "loss": 0.2154,
      "step": 470
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16651616990566254,
      "learning_rate": 0.0001282611546563382,
      "loss": 0.2138,
      "step": 480
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.19659796357154846,
      "learning_rate": 0.00012548765363864036,
      "loss": 0.248,
      "step": 490
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.21129171550273895,
      "learning_rate": 0.00012269302015919172,
      "loss": 0.2365,
      "step": 500
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.17871464788913727,
      "learning_rate": 0.00011987957131967418,
      "loss": 0.2163,
      "step": 510
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.20792001485824585,
      "learning_rate": 0.00011704963982206299,
      "loss": 0.2172,
      "step": 520
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.19423829019069672,
      "learning_rate": 0.00011420557203452444,
      "loss": 0.2237,
      "step": 530
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.18463781476020813,
      "learning_rate": 0.00011134972604598224,
      "loss": 0.2313,
      "step": 540
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.22249451279640198,
      "learning_rate": 0.00010848446971096606,
      "loss": 0.2215,
      "step": 550
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.18581299483776093,
      "learning_rate": 0.00010561217868636313,
      "loss": 0.2423,
      "step": 560
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.19015945494174957,
      "learning_rate": 0.0001027352344617007,
      "loss": 0.2333,
      "step": 570
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.19008071720600128,
      "learning_rate": 9.985602238459247e-05,
      "loss": 0.2337,
      "step": 580
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.17723417282104492,
      "learning_rate": 9.69769296829864e-05,
      "loss": 0.2597,
      "step": 590
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.15682680904865265,
      "learning_rate": 9.410034348585298e-05,
      "loss": 0.2344,
      "step": 600
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.2075541615486145,
      "learning_rate": 9.122864884395633e-05,
      "loss": 0.2431,
      "step": 610
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 0.1627311110496521,
      "learning_rate": 8.836422675234754e-05,
      "loss": 0.2093,
      "step": 620
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.1544761210680008,
      "learning_rate": 8.550945217622146e-05,
      "loss": 0.209,
      "step": 630
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 0.1808929443359375,
      "learning_rate": 8.266669208177252e-05,
      "loss": 0.1957,
      "step": 640
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.16527757048606873,
      "learning_rate": 7.983830347368276e-05,
      "loss": 0.2367,
      "step": 650
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.2052779644727707,
      "learning_rate": 7.702663144086957e-05,
      "loss": 0.2227,
      "step": 660
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 0.163204163312912,
      "learning_rate": 7.42340072121126e-05,
      "loss": 0.2082,
      "step": 670
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.16643495857715607,
      "learning_rate": 7.146274622317288e-05,
      "loss": 0.203,
      "step": 680
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.19465573132038116,
      "learning_rate": 6.871514619700594e-05,
      "loss": 0.1933,
      "step": 690
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.1858910173177719,
      "learning_rate": 6.599348523866155e-05,
      "loss": 0.2681,
      "step": 700
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 0.19610081613063812,
      "learning_rate": 6.33000199464487e-05,
      "loss": 0.1975,
      "step": 710
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.17338894307613373,
      "learning_rate": 6.063698354093255e-05,
      "loss": 0.2098,
      "step": 720
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 0.20726440846920013,
      "learning_rate": 5.800658401331467e-05,
      "loss": 0.2524,
      "step": 730
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 0.16990433633327484,
      "learning_rate": 5.5411002294730996e-05,
      "loss": 0.2554,
      "step": 740
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.18058453500270844,
      "learning_rate": 5.285239044798695e-05,
      "loss": 0.2303,
      "step": 750
    },
    {
      "epoch": 2.026666666666667,
      "grad_norm": 0.23370951414108276,
      "learning_rate": 5.0332869883226817e-05,
      "loss": 0.2668,
      "step": 760
    },
    {
      "epoch": 2.0533333333333332,
      "grad_norm": 0.18458636105060577,
      "learning_rate": 4.785452959901921e-05,
      "loss": 0.2447,
      "step": 770
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.17996077239513397,
      "learning_rate": 4.54194244503147e-05,
      "loss": 0.1941,
      "step": 780
    },
    {
      "epoch": 2.1066666666666665,
      "grad_norm": 0.17587876319885254,
      "learning_rate": 4.302957344471383e-05,
      "loss": 0.2158,
      "step": 790
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.21463511884212494,
      "learning_rate": 4.068695806845624e-05,
      "loss": 0.2365,
      "step": 800
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.21927684545516968,
      "learning_rate": 3.839352064352012e-05,
      "loss": 0.2203,
      "step": 810
    },
    {
      "epoch": 2.1866666666666665,
      "grad_norm": 0.17904478311538696,
      "learning_rate": 3.6151162717193764e-05,
      "loss": 0.1997,
      "step": 820
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 0.2343963086605072,
      "learning_rate": 3.396174348545413e-05,
      "loss": 0.2434,
      "step": 830
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.18433381617069244,
      "learning_rate": 3.182707825146056e-05,
      "loss": 0.2357,
      "step": 840
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 0.18597538769245148,
      "learning_rate": 2.9748936920440286e-05,
      "loss": 0.2095,
      "step": 850
    },
    {
      "epoch": 2.2933333333333334,
      "grad_norm": 0.1784776896238327,
      "learning_rate": 2.7729042532215456e-05,
      "loss": 0.21,
      "step": 860
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.16370630264282227,
      "learning_rate": 2.576906983258669e-05,
      "loss": 0.2279,
      "step": 870
    },
    {
      "epoch": 2.3466666666666667,
      "grad_norm": 0.18195076286792755,
      "learning_rate": 2.3870643884758913e-05,
      "loss": 0.2387,
      "step": 880
    },
    {
      "epoch": 2.3733333333333335,
      "grad_norm": 0.18079137802124023,
      "learning_rate": 2.203533872196003e-05,
      "loss": 0.2078,
      "step": 890
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.1958211362361908,
      "learning_rate": 2.0264676042370025e-05,
      "loss": 0.2366,
      "step": 900
    },
    {
      "epoch": 2.4266666666666667,
      "grad_norm": 0.18698708713054657,
      "learning_rate": 1.8560123947442298e-05,
      "loss": 0.2385,
      "step": 910
    },
    {
      "epoch": 2.453333333333333,
      "grad_norm": 0.15956971049308777,
      "learning_rate": 1.6923095724663297e-05,
      "loss": 0.1965,
      "step": 920
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.14962641894817352,
      "learning_rate": 1.535494867576016e-05,
      "loss": 0.2284,
      "step": 930
    },
    {
      "epoch": 2.506666666666667,
      "grad_norm": 0.17657926678657532,
      "learning_rate": 1.3856982991327128e-05,
      "loss": 0.2144,
      "step": 940
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.2020869255065918,
      "learning_rate": 1.2430440672804545e-05,
      "loss": 0.2081,
      "step": 950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.18659169971942902,
      "learning_rate": 1.1076504502703867e-05,
      "loss": 0.2319,
      "step": 960
    },
    {
      "epoch": 2.586666666666667,
      "grad_norm": 0.18576562404632568,
      "learning_rate": 9.796297063932614e-06,
      "loss": 0.1931,
      "step": 970
    },
    {
      "epoch": 2.6133333333333333,
      "grad_norm": 0.22051119804382324,
      "learning_rate": 8.590879809032349e-06,
      "loss": 0.2334,
      "step": 980
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.18060897290706635,
      "learning_rate": 7.461252180101352e-06,
      "loss": 0.2053,
      "step": 990
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.2077886462211609,
      "learning_rate": 6.408350780131778e-06,
      "loss": 0.2265,
      "step": 1000
    },
    {
      "epoch": 2.6933333333333334,
      "grad_norm": 0.1750851273536682,
      "learning_rate": 5.433048596448287e-06,
      "loss": 0.2162,
      "step": 1010
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.19976474344730377,
      "learning_rate": 4.5361542768921015e-06,
      "loss": 0.2041,
      "step": 1020
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 0.1684112697839737,
      "learning_rate": 3.718411459350446e-06,
      "loss": 0.2003,
      "step": 1030
    },
    {
      "epoch": 2.7733333333333334,
      "grad_norm": 0.18732760846614838,
      "learning_rate": 2.9804981551875054e-06,
      "loss": 0.2628,
      "step": 1040
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.18202297389507294,
      "learning_rate": 2.3230261870879956e-06,
      "loss": 0.2545,
      "step": 1050
    },
    {
      "epoch": 2.8266666666666667,
      "grad_norm": 0.18158504366874695,
      "learning_rate": 1.7465406817793296e-06,
      "loss": 0.2305,
      "step": 1060
    },
    {
      "epoch": 2.8533333333333335,
      "grad_norm": 0.15842077136039734,
      "learning_rate": 1.251519618053265e-06,
      "loss": 0.2217,
      "step": 1070
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.1563587337732315,
      "learning_rate": 8.383734304615143e-07,
      "loss": 0.2203,
      "step": 1080
    },
    {
      "epoch": 2.9066666666666667,
      "grad_norm": 0.1900392323732376,
      "learning_rate": 5.07444669013979e-07,
      "loss": 0.2324,
      "step": 1090
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.18550145626068115,
      "learning_rate": 2.5900771516188527e-07,
      "loss": 0.2335,
      "step": 1100
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.19895750284194946,
      "learning_rate": 9.326855430110692e-08,
      "loss": 0.2147,
      "step": 1110
    },
    {
      "epoch": 2.986666666666667,
      "grad_norm": 0.191454216837883,
      "learning_rate": 1.036460498445857e-08,
      "loss": 0.1963,
      "step": 1120
    }
  ],
  "logging_steps": 10,
  "max_steps": 1125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 375,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8633341100032e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
